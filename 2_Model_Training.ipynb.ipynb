{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee45f8a4-03b4-4e26-8b08-c497de72f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Training Script Started ---\n",
      "Loading 'upi_transactions.csv'...\n",
      "...Dataset loaded successfully.\n",
      "Creating new features...\n",
      "...'hour_of_day' feature created.\n",
      "\n",
      "--- Data Preview with New Feature ---\n",
      "   amount  hour_of_day\n",
      "0  370.46           12\n",
      "1  215.79           16\n",
      "2  127.39           20\n",
      "3  105.29            4\n",
      "4  198.03           10\n",
      "\n",
      "--- Data Summary ---\n",
      "Total data points: 1040\n",
      "Features for model: ['amount', 'hour_of_day']\n",
      "Number of fraudulent transactions in data: 40\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib # This is for saving our trained model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"--- Model Training Script Started ---\")\n",
    "\n",
    "# --- Step 1: Load the Dataset ---\n",
    "print(\"Loading 'upi_transactions.csv'...\")\n",
    "try:\n",
    "    df = pd.read_csv('upi_transactions.csv')\n",
    "    # Convert timestamp column back to datetime objects\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    print(\"...Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'upi_transactions.csv' not found. Please ensure it is in the same folder.\")\n",
    "    # Stop execution if the file doesn't exist\n",
    "\n",
    "# --- Step 2: Feature Engineering ---\n",
    "# Machine learning models work with numbers. We will create numerical features \n",
    "# that help the model understand the data.\n",
    "\n",
    "print(\"Creating new features...\")\n",
    "\n",
    "# Create a 'hour_of_day' feature from the timestamp\n",
    "# This is very important for detecting fraud at unusual times\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "\n",
    "print(\"...'hour_of_day' feature created.\")\n",
    "print(\"\\n--- Data Preview with New Feature ---\")\n",
    "# We select only the numerical columns our model will use\n",
    "# For this project, 'amount' and 'hour_of_day' are our key features.\n",
    "features = ['amount', 'hour_of_day']\n",
    "X = df[features]\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Display the first few rows of our feature set\n",
    "print(X.head())\n",
    "\n",
    "# Display a summary of our data\n",
    "print(\"\\n--- Data Summary ---\")\n",
    "print(f\"Total data points: {len(df)}\")\n",
    "print(f\"Features for model: {features}\")\n",
    "print(f\"Number of fraudulent transactions in data: {y.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cdb533-fe55-435c-af3f-b967c96055bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating features...\n",
      "...Data loaded successfully.\n",
      "\n",
      "Training the Isolation Forest model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Model training complete.\n",
      "Model saved to 'fraud_model.joblib'\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.99      0.99      0.99      1000\n",
      "   Fraud (1)       0.78      0.78      0.78        40\n",
      "\n",
      "    accuracy                           0.98      1040\n",
      "   macro avg       0.88      0.88      0.88      1040\n",
      "weighted avg       0.98      0.98      0.98      1040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Imports and Data Loading ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ADDED THIS SECTION TO FIX THE 'X not defined' ERROR\n",
    "# This ensures our script always has the data it needs to run.\n",
    "print(\"Loading data and creating features...\")\n",
    "try:\n",
    "    df = pd.read_csv('upi_transactions.csv')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "    \n",
    "    features = ['amount', 'hour_of_day']\n",
    "    X = df[features]\n",
    "    y = df['is_fraud']\n",
    "    print(\"...Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"FATAL ERROR: 'upi_transactions.csv' not found. Please run the data generation notebook first.\")\n",
    "    # In a real script, you'd exit. Here we'll stop by not running the rest.\n",
    "\n",
    "\n",
    "# --- Step 3: Train the Anomaly Detection Model ---\n",
    "\n",
    "# The 'contamination' parameter is the most important one.\n",
    "# It tells the model what proportion of the data is expected to be anomalous (fraudulent).\n",
    "# We calculate it dynamically now.\n",
    "contamination_rate = y.mean() # The mean of a binary (0/1) column is the proportion of 1s\n",
    "model = IsolationForest(n_estimators=100, contamination=contamination_rate, random_state=42)\n",
    "\n",
    "print(\"\\nTraining the Isolation Forest model...\")\n",
    "\n",
    "# We train the model on our feature set 'X'\n",
    "model.fit(X)\n",
    "\n",
    "print(\"...Model training complete.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Save the Trained Model ---\n",
    "# We save the model to a file so our application can use it later\n",
    "joblib.dump(model, 'fraud_model.joblib')\n",
    "print(\"Model saved to 'fraud_model.joblib'\")\n",
    "\n",
    "\n",
    "# --- Step 5: Evaluate the Model's Performance ---\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "# Let's see how well our model did. We'll make predictions on the whole dataset.\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# The model outputs -1 for anomalies (fraud) and 1 for normal transactions.\n",
    "# We need to convert this to our format (1 for fraud, 0 for normal).\n",
    "pred_labels = np.where(predictions == -1, 1, 0)\n",
    "\n",
    "# Now we compare the model's predictions (pred_labels) with the true labels (y)\n",
    "report = classification_report(y, pred_labels, target_names=['Normal (0)', 'Fraud (1)'])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd026b-12c5-4af9-8af7-2d5676c2cb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
